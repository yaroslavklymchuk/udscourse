{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python36\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\python36\\lib\\site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score as score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.snowball import EnglishStemmer\n",
    "#from spacy.tokens import Doc\n",
    "import en_core_web_sm\n",
    "import re\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "data_train = pd.read_csv('E:\\\\PycharmProjects\\\\Machine_L\\\\Data_Science_Club\\\\second_\\\\train.csv')\n",
    "data_test = pd.read_csv('E:\\\\PycharmProjects\\\\Machine_L\\\\Data_Science_Club\\\\second_\\\\test.csv')\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "#porter_stemmer = PorterStemmer()\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "en_lp = en_core_web_sm.load()\n",
    "'''\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "'''\n",
    "def tokenizer_(doc):\n",
    "    doc_spacy = en_lp(doc)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "all_text = pd.concat([data_train['comment_text'], data_test['comment_text']])\n",
    "vectorizer_tf_new = TfidfVectorizer(min_df = 5, max_df = 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=40000, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tf_new.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'has'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tf_new.get_feature_names()[np.argsort(vectorizer_tf_new.idf_)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = f.sum(axis=0).A1\n",
    "vocab = vect_Count.get_feature_names()\n",
    "freq_distribution = Counter(dict(zip(vocab, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 918456)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_distribution.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "f = io.open('Top word.txt', 'w', encoding = 'utf-8')\n",
    "f.write(freq_distribution.most_common(1)[0][0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_fet_tf = vectorizer_tf_new.transform(data_train['comment_text'])\n",
    "test_text_tf = vectorizer_tf_new.transform(data_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=40000, max_features=200, min_df=5,\n",
       "        ngram_range=(2, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df = 5, ngram_range =(2,2), binary = True, lowercase = True, max_df = 40000, max_features = 200)\n",
    "vect.fit(data_train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = vect.transform(data_train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 40000) (159571, 200)\n"
     ]
    }
   ],
   "source": [
    "print(train_text_fet_tf.shape, train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "new_text_features_tr = hstack((train_text_fet_tf, train_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 40200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_features_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one of', 'out of', 'page and', 'part of', 'please do']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = vect_1.transform(data_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_features = hstack((test_text_tf, test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 40200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928478365463265\n",
      "{'C': 1e-05}\n",
      "0.9286024677719219\n",
      "{'C': 0.0001}\n",
      "0.9298556631937356\n",
      "{'C': 0.001}\n",
      "0.9378137321904801\n",
      "{'C': 0.01}\n",
      "0.9555242854905465\n",
      "{'C': 0.1}\n",
      "0.9695307870596787\n",
      "{'C': 1.0}\n",
      "0.9681634213084327\n",
      "{'C': 10.0}\n",
      "0.9539647410432956\n",
      "{'C': 100.0}\n",
      "0.9449230101626989\n",
      "{'C': 1000.0}\n",
      "0.9436467566244757\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820399726591208\n",
      "{'C': 1e-05}\n",
      "0.9820399134496522\n",
      "{'C': 0.0001}\n",
      "0.9820607193790238\n",
      "{'C': 0.001}\n",
      "0.9822462921730389\n",
      "{'C': 0.01}\n",
      "0.9841840591798116\n",
      "{'C': 0.1}\n",
      "0.9851422839633204\n",
      "{'C': 1.0}\n",
      "0.9783589783342337\n",
      "{'C': 10.0}\n",
      "0.9598308151340567\n",
      "{'C': 100.0}\n",
      "0.9469985814119115\n",
      "{'C': 1000.0}\n",
      "0.9453271071848721\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9648158823487971\n",
      "{'C': 1e-05}\n",
      "0.9648434776757323\n",
      "{'C': 0.0001}\n",
      "0.9653046037077556\n",
      "{'C': 0.001}\n",
      "0.9686944138042087\n",
      "{'C': 0.01}\n",
      "0.9772052437161367\n",
      "{'C': 0.1}\n",
      "0.9844710810310291\n",
      "{'C': 1.0}\n",
      "0.9813291085701051\n",
      "{'C': 10.0}\n",
      "0.9675076701686595\n",
      "{'C': 100.0}\n",
      "0.9586366777890797\n",
      "{'C': 1000.0}\n",
      "0.9574782184181797\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9762740498503932\n",
      "{'C': 1e-05}\n",
      "0.9762744191914011\n",
      "{'C': 0.0001}\n",
      "0.9762827768008695\n",
      "{'C': 0.001}\n",
      "0.9763485067812087\n",
      "{'C': 0.01}\n",
      "0.9771891777811023\n",
      "{'C': 0.1}\n",
      "0.984207950270494\n",
      "{'C': 1.0}\n",
      "0.9833407447519212\n",
      "{'C': 10.0}\n",
      "0.9740549025709279\n",
      "{'C': 100.0}\n",
      "0.9660563630159232\n",
      "{'C': 1000.0}\n",
      "0.9648669477243479\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541497306338828\n",
      "{'C': 1e-05}\n",
      "0.9542079113567064\n",
      "{'C': 0.0001}\n",
      "0.9546431390778297\n",
      "{'C': 0.001}\n",
      "0.9581654822347577\n",
      "{'C': 0.01}\n",
      "0.9681134417674748\n",
      "{'C': 0.1}\n",
      "0.9759069597647939\n",
      "{'C': 1.0}\n",
      "0.9712218246675351\n",
      "{'C': 10.0}\n",
      "0.9498697929406463\n",
      "{'C': 100.0}\n",
      "0.934771056661363\n",
      "{'C': 1000.0}\n",
      "0.9324473379238438\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9599685749350547\n",
      "{'C': 1e-05}\n",
      "0.9599679579138499\n",
      "{'C': 0.0001}\n",
      "0.9600321637984929\n",
      "{'C': 0.001}\n",
      "0.96065406075122\n",
      "{'C': 0.01}\n",
      "0.9662516745148718\n",
      "{'C': 0.1}\n",
      "0.9745979542055193\n",
      "{'C': 1.0}\n",
      "0.9700332992687818\n",
      "{'C': 10.0}\n",
      "0.9533663144074774\n",
      "{'C': 100.0}\n",
      "0.9431935749217742\n",
      "{'C': 1000.0}\n",
      "0.9414183079548111\n",
      "{'C': 10000.0}\n"
     ]
    }
   ],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5,5))}\n",
    "scores_vectorizer_tf =[] \n",
    "best_params_vectorizer_tf = []\n",
    "for cl_name in class_names:\n",
    "    y_train = data_train[cl_name]\n",
    "    gs = GridSearchCV(LogisticRegression(penalty = 'l2', solver = 'sag'), grid, n_jobs = -1, scoring = 'roc_auc', cv=KFold(n_splits = 5, shuffle = True, random_state = 241))\n",
    "    gs.fit(train_text_fet_tf, y_train)\n",
    "    scores_vectorizer_tf.append(gs.best_score_)\n",
    "    best_params_vectorizer_tf.append(gs.best_params_)\n",
    "    for scores in gs.grid_scores_:\n",
    "        print(scores.mean_validation_score)\n",
    "        print(scores.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Cross-validation scores sag and TfidfVect(min_df = 5, max_df = 40000).txt', 'w')\n",
    "f.write('logRegression with C-parameters founded by GridSearchCV')\n",
    "f.write('\\n')\n",
    "for i in range(len(scores_vectorizer_tf)):\n",
    "    f.write(class_names[i])\n",
    "    f.write(' ')\n",
    "    f.write(str(best_params_vectorizer_tf[i]))\n",
    "    f.write(' ')\n",
    "    f.write(str(scores_vectorizer_tf[i]))\n",
    "    f.write('\\n')\n",
    "f.write('\\n')\n",
    "f.write('Mean of scores for all classes ')\n",
    "f.write(str(np.mean(scores_vectorizer_tf)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': data_test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_par = [1, 1, 1, 1, 1, 1]\n",
    "for cl_name, C_par in zip(class_names, C_par):\n",
    "    clf = LogisticRegression(C = C_par, solver = 'sag')\n",
    "    y_train = data_train[cl_name]\n",
    "    clf.fit(train_text_fet_tf, y_train)\n",
    "    submission[cl_name] = clf.predict_proba(test_text_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_nine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'log_c': 1, 'log_pen': 'l1', 'tf_max': 40000}\n",
    "d['log_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
