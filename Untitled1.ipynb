{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python36\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\python36\\lib\\site-packages (from nltk)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score as score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.snowball import EnglishStemmer\n",
    "#from spacy.tokens import Doc\n",
    "import en_core_web_sm\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "data_train = pd.read_csv('E:\\\\PycharmProjects\\\\Machine_L\\\\Data_Science_Club\\\\second_\\\\train.csv')\n",
    "data_test = pd.read_csv('E:\\\\PycharmProjects\\\\Machine_L\\\\Data_Science_Club\\\\second_\\\\test.csv')\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "#porter_stemmer = PorterStemmer()\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "en_lp = en_core_web_sm.load()\n",
    "'''\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "'''\n",
    "def tokenizer_(doc):\n",
    "    doc_spacy = en_lp(doc)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "all_text = pd.concat([data_train['comment_text'], data_test['comment_text']])\n",
    "vectorizer_tf_new = TfidfVectorizer(min_df = 5, max_df = 40000, tokenizer = LemmaTokenizer(), max_features = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=40000, max_features=50000, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<__main__.LemmaTokenizer object at 0x1512CB30>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tf_new.fit(data_train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_fet_tf = vectorizer_tf_new.transform(data_train['comment_text'])\n",
    "#test_text_tf = vectorizer_tf_new.transform(data_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=40000, max_features=50000, min_df=5,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<__main__.LemmaTokenizer object at 0x465DDE50>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df = 5, max_df = 40000, tokenizer = LemmaTokenizer(), max_features = 50000)\n",
    "vect.fit(data_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_tf = vect.transform(data_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 35574) (153164, 35589)\n"
     ]
    }
   ],
   "source": [
    "print(train_text_fet_tf.shape, test_text_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_fet_tf = train_text_fet_tf.tocsr()\n",
    "test_text_tf = test_text_tf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 36433) (153164, 36652)\n"
     ]
    }
   ],
   "source": [
    "print(final_train.shape, final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_train.tocsr()\n",
    "final_test = final_test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa86cfcde2fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m36433\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(final_train.shape, final_test[:, :36433].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704831468792588\n",
      "{'C': 1e-05}\n",
      "0.7663021521546297\n",
      "{'C': 0.0001}\n",
      "0.8547250117900096\n",
      "{'C': 0.001}\n",
      "0.9015626493707192\n",
      "{'C': 0.01}\n",
      "0.9494851620994631\n",
      "{'C': 0.1}\n",
      "0.9707606516443819\n",
      "{'C': 1.0}\n",
      "0.96979887898172\n",
      "{'C': 10.0}\n",
      "0.9555199238930907\n",
      "{'C': 100.0}\n",
      "0.9386500703019269\n",
      "{'C': 1000.0}\n",
      "0.9362345358055615\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734339389725009\n",
      "{'C': 1e-05}\n",
      "0.8001961601913044\n",
      "{'C': 0.0001}\n",
      "0.8935110284824871\n",
      "{'C': 0.001}\n",
      "0.9622794048131068\n",
      "{'C': 0.01}\n",
      "0.977068100797531\n",
      "{'C': 0.1}\n",
      "0.9823820915346816\n",
      "{'C': 1.0}\n",
      "0.9768832987749664\n",
      "{'C': 10.0}\n",
      "0.9595560876277066\n",
      "{'C': 100.0}\n",
      "0.9362559534006939\n",
      "{'C': 1000.0}\n",
      "0.9116928049286765\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192267827102717\n",
      "{'C': 1e-05}\n",
      "0.7740294143265528\n",
      "{'C': 0.0001}\n",
      "0.8806382766936369\n",
      "{'C': 0.001}\n",
      "0.9305813904702277\n",
      "{'C': 0.01}\n",
      "0.9670671618733702\n",
      "{'C': 0.1}\n",
      "0.9832350836266365\n",
      "{'C': 1.0}\n",
      "0.981004554159207\n",
      "{'C': 10.0}\n",
      "0.966811163299404\n",
      "{'C': 100.0}\n",
      "0.9497412879051438\n",
      "{'C': 1000.0}\n",
      "0.9385440521386926\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6734066900381408\n",
      "{'C': 1e-05}\n",
      "0.6819590714272085\n",
      "{'C': 0.0001}\n",
      "0.7355190846466416\n",
      "{'C': 0.001}\n",
      "0.8929100616864595\n",
      "{'C': 0.01}\n",
      "0.9571880848767721\n",
      "{'C': 0.1}\n",
      "0.9781881387228577\n",
      "{'C': 1.0}\n",
      "0.9794743011768854\n",
      "{'C': 10.0}\n",
      "0.9708873996806097\n",
      "{'C': 100.0}\n",
      "0.9608378761466684\n",
      "{'C': 1000.0}\n",
      "0.9526329573624038\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148029410305456\n",
      "{'C': 1e-05}\n",
      "0.7718314257444101\n",
      "{'C': 0.0001}\n",
      "0.876495048627621\n",
      "{'C': 0.001}\n",
      "0.92408246888462\n",
      "{'C': 0.01}\n",
      "0.9597041653282099\n",
      "{'C': 0.1}\n",
      "0.9756999272943414\n",
      "{'C': 1.0}\n",
      "0.9723365943385417\n",
      "{'C': 10.0}\n",
      "0.9517090403956837\n",
      "{'C': 100.0}\n",
      "0.9256104596487126\n",
      "{'C': 1000.0}\n",
      "0.9192212847715895\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7027008993050082\n",
      "{'C': 1e-05}\n",
      "0.7171707597843893\n",
      "{'C': 0.0001}\n",
      "0.7878111235394603\n",
      "{'C': 0.001}\n",
      "0.8904795124846699\n",
      "{'C': 0.01}\n",
      "0.9419829626784878\n",
      "{'C': 0.1}\n",
      "0.9683564355074306\n",
      "{'C': 1.0}\n",
      "0.9653628313572629\n",
      "{'C': 10.0}\n",
      "0.9491997246661145\n",
      "{'C': 100.0}\n",
      "0.9317631034803635\n",
      "{'C': 1000.0}\n",
      "0.9078514455065123\n",
      "{'C': 10000.0}\n"
     ]
    }
   ],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 5))}\n",
    "scores_vectorizer_tf = []\n",
    "best_params_vectorizer_tf = []\n",
    "for cl_name in class_names:\n",
    "    y_train = data_train[cl_name]\n",
    "    gs = GridSearchCV(LogisticRegression(penalty = 'l2'), grid, n_jobs = -1, scoring = 'roc_auc', cv=KFold(n_splits = 5, shuffle = True, random_state = 241))\n",
    "    gs.fit(final_train, y_train)\n",
    "    scores_vectorizer_tf.append(gs.best_score_)\n",
    "    best_params_vectorizer_tf.append(gs.best_params_)\n",
    "    for scores in gs.grid_scores_:\n",
    "        print(scores.mean_validation_score)\n",
    "        print(scores.parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764370453333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [0.9683564, 0.97569992, 0.97818813, 0.98323508, 0.982382091, 0.970760651]\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1.0}, {'C': 1.0}, {'C': 1.0}, {'C': 10.0}, {'C': 1.0}, {'C': 1.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_vectorizer_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': data_test['id']})\n",
    "C = [1,1,1,10,1,1]\n",
    "for cl_name, C_par in zip(class_names, C):\n",
    "    clf = LogisticRegression(C = C_par, penalty = 'l2')\n",
    "    y_train = data_train[cl_name]\n",
    "    clf.fit(final_train, y_train)\n",
    "    submission[cl_name] = clf.predict_proba(final_test)[:, 1]\n",
    "submission.to_csv('submission_another.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
